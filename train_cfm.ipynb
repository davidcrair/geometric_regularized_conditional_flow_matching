{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import scanpy as sc\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ae_model import Autoencoder\n",
    "from neural_flow_model import FlowModel, ZINBSampler\n",
    "from datasets import PerturbPairData\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f99640",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 2048\n",
    "HIDDEN_DIM = 128\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "COND_EMB_DIMS = 16\n",
    "PERT_EMB_DIMS = 16\n",
    "SIGMA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550323a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jiang(path: str):\n",
    "    adata = sc.read_h5ad(path)\n",
    "    # adata = adata[adata.obs[\"cell_type\"] == 'ht29']\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.tl.pca(adata, svd_solver=\"arpack\")\n",
    "    return adata\n",
    "\n",
    "def load_pbmc(path: str):\n",
    "    adata = sc.read_h5ad(path)\n",
    "    adata.layers[\"counts\"] = adata.X.copy()\n",
    "    adata.obs['perturbation'] = adata.obs['cytokine']\n",
    "    adata.obs['control'] = (adata.obs['cytokine'] == 'PBS').astype(int)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.tl.pca(adata, svd_solver=\"arpack\")\n",
    "    return adata\n",
    "\n",
    "\n",
    "print(\"loading dataset\")\n",
    "adata = load_pbmc(\n",
    "    path=\"data/pmbc_c14_mono_all_donors_20k_subset.h5ad\"\n",
    ")\n",
    "\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"models/model_geodesic_c14_mono_all_donors_20k_dim32.pt\", map_location=device)\n",
    "\n",
    "model_ae = Autoencoder(\n",
    "    input_dim=ckpt[\"input_dim\"],\n",
    "    latent_dim=ckpt[\"latent_dim\"],\n",
    "    hidden_dim=ckpt[\"hidden_dim\"],\n",
    ").to(device)\n",
    "model_ae.load_state_dict(ckpt[\"model_state\"])\n",
    "model_ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ce095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pca = torch.from_numpy(adata.obsm[\"X_pca\"].astype(\"float32\")).to(device)\n",
    "with torch.no_grad():\n",
    "    X = model_ae.encode(torch.from_numpy(adata.X.toarray().astype(\"float32\")).to(device))\n",
    "\n",
    "# X = torch.from_numpy(adata.X.toarray().astype(\"float32\")).to(device) # use raw gene\n",
    "# X = X_pca # use PCA\n",
    "X = X # use latent space of AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fab3dd",
   "metadata": {},
   "source": [
    "### Create mapping of perturbation and condition to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERTURBATION_COL = 'perturbation'\n",
    "CONDITION_COL = 'cell_type'\n",
    "CONTROL_COL = 'control'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12318936",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conditions = sorted(adata.obs[CONDITION_COL].unique())\n",
    "all_perturbations = sorted(adata.obs[PERTURBATION_COL].unique())\n",
    "\n",
    "global_condition_to_idx = {cond: i for i, cond in enumerate(all_conditions)}\n",
    "global_perturb_to_idx = {pert: i for i, pert in enumerate(all_perturbations)}\n",
    "\n",
    "print(f\"total # conditions: {len(global_condition_to_idx)}\")\n",
    "print(f\"total # perturbs: {len(global_perturb_to_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ca45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tensors(dataset):\n",
    "    c_idxs = [item[0] for item in dataset.pairs]\n",
    "    q_idxs = [item[1] for item in dataset.pairs]\n",
    "    p_idxs = [dataset.perturb_to_idx[item[2]] for item in dataset.pairs]\n",
    "    cond_idxs = [dataset.condition_to_idx[item[3]] for item in dataset.pairs]\n",
    "    return (\n",
    "        dataset.X[c_idxs],\n",
    "        dataset.X[q_idxs],\n",
    "        torch.tensor(p_idxs, device=device),\n",
    "        torch.tensor(cond_idxs, device=device)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def compute_mmd(x_true, x_pred, gamma=None):\n",
    "    if x_true.shape[0] > 2000:\n",
    "        idx = np.random.choice(x_true.shape[0], 2000, replace=False)\n",
    "        x_true = x_true[idx]\n",
    "\n",
    "    if x_pred.shape[0] > 2000:\n",
    "        idx = np.random.choice(x_pred.shape[0], 2000, replace=False)\n",
    "        x_pred = x_pred[idx]\n",
    "\n",
    "    K_xx = rbf_kernel(x_true, x_true, gamma=gamma)\n",
    "    K_yy = rbf_kernel(x_pred, x_pred, gamma=gamma)\n",
    "    K_xy = rbf_kernel(x_true, x_pred, gamma=gamma)\n",
    "\n",
    "    return K_xx.mean() + K_yy.mean() - 2 * K_xy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wd_per_gene(x_true, x_pred):\n",
    "    n_genes = x_true.shape[1]\n",
    "    wds = []\n",
    "    for i in range(n_genes):\n",
    "        wd = wasserstein_distance(x_true[:, i], x_pred[:, i])\n",
    "        wds.append(wd)\n",
    "    return np.array(wds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01c7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_donors = sorted(adata.obs['donor'].unique())\n",
    "results = []\n",
    "\n",
    "all_wds = []\n",
    "all_deg_wds = []\n",
    "\n",
    "for holdout_donor in all_donors:\n",
    "    print(f\"--- holding out {holdout_donor} ---\")\n",
    "\n",
    "    donor_mask = (adata.obs[\"donor\"] == holdout_donor).to_numpy()\n",
    "    ctrl_mask  = adata.obs[CONTROL_COL].to_numpy().astype(bool)\n",
    "\n",
    "    donor_perts = list(adata.obs.loc[donor_mask & (~ctrl_mask), PERTURBATION_COL].unique())\n",
    "\n",
    "    rng = np.random.default_rng(42)\n",
    "    heldout_perts = rng.choice(\n",
    "        donor_perts,\n",
    "        size=max(1, int(np.ceil(0.30 * len(donor_perts)))),\n",
    "        replace=False,\n",
    "    )\n",
    "\n",
    "    print(f'holding out perturbations: {heldout_perts}')\n",
    "\n",
    "    test_mask = donor_mask & (ctrl_mask | adata.obs[PERTURBATION_COL].isin(heldout_perts).to_numpy())\n",
    "    train_mask = ~ (donor_mask & adata.obs[PERTURBATION_COL].isin(heldout_perts).to_numpy())\n",
    "    train_idx = np.where(train_mask)[0]\n",
    "    test_idx  = np.where(test_mask)[0]\n",
    "\n",
    "    X_train = X[train_idx]\n",
    "    X_test  = X[test_idx]\n",
    "    \n",
    "    obs_train = adata.obs.iloc[train_idx].copy()\n",
    "    obs_test  = adata.obs.iloc[test_idx].copy()\n",
    "\n",
    "    train_dataset = PerturbPairData(\n",
    "        X_train,\n",
    "        obs=obs_train,\n",
    "        perturb_col=\"perturbation\",\n",
    "        control_col=\"control\",\n",
    "        condition_col=\"cell_type\",\n",
    "        seed=42,\n",
    "        device=device,\n",
    "        perturb_to_idx=global_perturb_to_idx,\n",
    "        condition_to_idx=global_condition_to_idx\n",
    "    )\n",
    "    test_dataset = PerturbPairData(\n",
    "        X_test,\n",
    "        obs=obs_test,\n",
    "        perturb_col=\"perturbation\",\n",
    "        control_col=\"control\",\n",
    "        condition_col=\"cell_type\",\n",
    "        seed=43,\n",
    "        device=device,\n",
    "        perturb_to_idx=global_perturb_to_idx,\n",
    "        condition_to_idx=global_condition_to_idx\n",
    "    )\n",
    "\n",
    "    train_x0, train_x1, train_p, train_c = prepare_tensors(train_dataset)\n",
    "    test_x0, test_x1, test_p, test_c = prepare_tensors(test_dataset)\n",
    "\n",
    "    flow_model = FlowModel(\n",
    "        dim=X.shape[1],\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        conditional_model=True,\n",
    "        num_conditions=train_dataset.num_conditions(),\n",
    "        num_perturbs=len(adata.obs['perturbation'].unique()),\n",
    "        condition_embedding_dim=COND_EMB_DIMS,\n",
    "        perturb_embedding_dim=PERT_EMB_DIMS,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(flow_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    loss_fn = nn.HuberLoss(delta=1.0)\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    n_train = train_x0.shape[0]\n",
    "    n_test = test_x0.shape[0]\n",
    "\n",
    "    for epoch in tqdm(range(NUM_EPOCHS), desc=\"Training\"):\n",
    "        perm = torch.randperm(n_train, device=device)\n",
    "        flow_model.train()\n",
    "        train_loss_sum_epoch = 0.0\n",
    "        # train_loss_sum_pear_corr = 0.0\n",
    "        train_n_epoch = 0\n",
    "\n",
    "        for i in range(0, n_train, BATCH_SIZE):\n",
    "            idx = perm[i : i + BATCH_SIZE]\n",
    "\n",
    "            x_0 = train_x0[idx]\n",
    "            x_1 = train_x1[idx]\n",
    "\n",
    "            # add noise\n",
    "            sigma = SIGMA\n",
    "            x_0 = x_0 + torch.randn_like(x_0) * sigma\n",
    "            x_1 = x_1 + torch.randn_like(x_1) * sigma\n",
    "\n",
    "            perturb = train_p[idx]\n",
    "            ct = train_c[idx]\n",
    "            t = torch.rand(len(x_1), 1, device=device)\n",
    "\n",
    "            x_t = (1 - t) * x_0 + t * x_1\n",
    "            dx_t = x_1 - x_0\n",
    "\n",
    "            pred = flow_model(x_t, t, perturb, ct)\n",
    "\n",
    "            # pear_corr = torch.corrcoef(torch.stack([dx_t.ravel(), pred.ravel()]))[0, 1]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(pred, dx_t)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_sum_epoch += loss.item() * x_1.size(0)\n",
    "            # train_loss_sum_pear_corr += pear_corr * x_1.size(0)\n",
    "            train_n_epoch += x_1.size(0)\n",
    "\n",
    "        avg_train_loss = train_loss_sum_epoch / max(train_n_epoch, 1)\n",
    "        # avg_train_pear_corr = train_loss_sum_pear_corr / max(train_n_epoch, 1)\n",
    "\n",
    "        flow_model.eval()\n",
    "\n",
    "        test_loss_sum_epoch = 0.0\n",
    "        test_loss_sum_pear_corr = 0.0\n",
    "        test_n_epoch = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, n_test, BATCH_SIZE):\n",
    "                x_0 = test_x0[i: i+BATCH_SIZE]\n",
    "                x_1 = test_x1[i: i+BATCH_SIZE]\n",
    "                perturb = test_p[i: i+BATCH_SIZE]\n",
    "                ct = test_c[i: i+BATCH_SIZE]\n",
    "                t = torch.rand(len(x_1), 1, device=device)\n",
    "\n",
    "                x_t = (1 - t) * x_0 + t * x_1\n",
    "                dx_t = x_1 - x_0\n",
    "\n",
    "                pred = flow_model(x_t, t, perturb, ct)\n",
    "                loss = loss_fn(pred, dx_t)\n",
    "\n",
    "                # pear_corr = torch.corrcoef(torch.stack([dx_t.ravel(), pred.ravel()]))[0, 1]\n",
    "\n",
    "                test_loss_sum_epoch += loss.item() * x_1.size(0)\n",
    "                # test_loss_sum_pear_corr += pear_corr * x_1.size(0)\n",
    "                test_n_epoch += x_1.size(0)\n",
    "\n",
    "        avg_test_loss = test_loss_sum_epoch / max(test_n_epoch, 1)\n",
    "        # avg_test_pear_corr = test_loss_sum_pear_corr / max(test_n_epoch, 1)\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        test_losses.append(avg_test_loss)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{NUM_EPOCHS}] | train loss: {avg_train_loss:.6f} | test loss: {avg_test_loss:.6f}\")\n",
    "\n",
    "    sampler = ZINBSampler(model_ae, device=device)\n",
    "\n",
    "    wds = []\n",
    "    deg_wds_list = []\n",
    "\n",
    "    for pert in heldout_perts:\n",
    "\n",
    "        try:\n",
    "            treated_mask = (adata.obs['perturbation'] == pert) & (adata.obs['donor'] == holdout_donor)\n",
    "            # treated_mask = (adata.obs['perturbation'] == pert) & (adata.obs['donor'] != holdout_donor)\n",
    "            # print(treated_mask.sum())\n",
    "\n",
    "            X_ctrl = torch.from_numpy(adata[ctrl_mask].X.toarray().astype(\"float32\")).to(device)\n",
    "            X_actual_treated_raw = torch.from_numpy(adata[treated_mask].layers['counts'].toarray().astype(\"float32\")).to(device)\n",
    "            library_sizes = torch.from_numpy(adata.layers['counts'][ctrl_mask].sum(1)).float().to(device)\n",
    "\n",
    "            adata_deg = adata[ctrl_mask | treated_mask].copy()\n",
    "\n",
    "            sc.tl.rank_genes_groups(\n",
    "                adata_deg,\n",
    "                groupby='cytokine',\n",
    "                groups=[pert],\n",
    "                reference='PBS',\n",
    "                method='wilcoxon'\n",
    "            )\n",
    "\n",
    "            de_results_df = sc.get.rank_genes_groups_df(\n",
    "                adata_deg,\n",
    "                group=pert\n",
    "            )\n",
    "\n",
    "            top_degs = de_results_df[\n",
    "                (de_results_df['pvals_adj'] < 0.05) & \n",
    "                (np.abs(de_results_df['logfoldchanges']) > 0.5)\n",
    "            ]\n",
    "\n",
    "            # print(f\"len(top_degs): {len(top_degs)}\")\n",
    "\n",
    "            pert_degs = top_degs['names'].values.tolist()\n",
    "\n",
    "            # print(pert_degs)\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                z_control = model_ae.encode(X_ctrl)\n",
    "\n",
    "                pert_idx = torch.tensor([global_perturb_to_idx[pert]] * X_ctrl.shape[0], device=device)\n",
    "                control_cell_types = adata.obs.loc[ctrl_mask, 'cell_type'].values\n",
    "                cond_indices = [global_condition_to_idx[ct] for ct in control_cell_types]\n",
    "                cond_tensor = torch.tensor(cond_indices, device=device)\n",
    "\n",
    "                z_pred = flow_model.integrate(\n",
    "                        x0=z_control, \n",
    "                        t0=0.0, \n",
    "                        t1=1.0, \n",
    "                        perturbations=pert_idx,\n",
    "                        conditions=cond_tensor\n",
    "                    )\n",
    "\n",
    "                X_pred_treated_raw = sampler.sample(z_pred, library_sizes)\n",
    "\n",
    "                wd_gene = compute_wd_per_gene(X_pred_treated_raw.cpu(), X_actual_treated_raw.cpu())\n",
    "\n",
    "                # print(f'mean wd on test data: {wd_gene.mean()}')\n",
    "            \n",
    "                wds.append(wd_gene)\n",
    "\n",
    "                deg_indices = [adata.var_names.get_loc(g) for g in pert_degs if g in adata.var_names]\n",
    "                wd_degs = wd_gene[deg_indices]\n",
    "                deg_wds_list.extend(wd_degs)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    mean_wd = np.array(wds).mean()\n",
    "        \n",
    "    print(f'mean wd across all genes and perts: {mean_wd:.4f}')\n",
    "\n",
    "    all_wds.append(mean_wd)\n",
    "\n",
    "    mean_deg_wg = np.array(deg_wds_list).mean()\n",
    "\n",
    "    print(f'mean deg wd across all genes and perts: {mean_deg_wg:.4f}')\n",
    "\n",
    "    all_deg_wds.append(mean_deg_wg)\n",
    "\n",
    "    break # remove this if you want to train on all splits\n",
    "\n",
    "print(f\"cv mean wd: {np.array(all_wds).mean():.4f}\")\n",
    "print(f\"cv mean deg wd: {np.array(all_deg_wds).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "go.Figure([\n",
    "    go.Scatter(y=train_losses, name=\"train\"),\n",
    "    go.Scatter(y=test_losses, name=\"test\"),\n",
    "]).update_layout(xaxis_title=\"epoch\", yaxis_title=\"loss\", yaxis=dict(range=[0, None])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48680e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wds = []\n",
    "# deg_wds_list = []\n",
    "\n",
    "# for pert in heldout_perts:\n",
    "#     # treated_mask = (adata.obs['perturbation'] == pert) & (adata.obs['donor'] == holdout_donor)\n",
    "#     treated_mask = (adata.obs['perturbation'] == pert) & (adata.obs['donor'] != holdout_donor)\n",
    "#     # print(treated_mask.sum())\n",
    "\n",
    "#     X_ctrl = torch.from_numpy(adata[ctrl_mask].X.toarray().astype(\"float32\")).to(device)\n",
    "#     X_actual_treated_raw = torch.from_numpy(adata[treated_mask].layers['counts'].toarray().astype(\"float32\")).to(device)\n",
    "#     library_sizes = torch.from_numpy(adata.layers['counts'][ctrl_mask].sum(1)).float().to(device)\n",
    "\n",
    "#     adata_deg = adata[ctrl_mask | treated_mask].copy()\n",
    "\n",
    "#     sc.tl.rank_genes_groups(\n",
    "#         adata_deg,\n",
    "#         groupby='cytokine',\n",
    "#         groups=[pert],\n",
    "#         reference='PBS',\n",
    "#         method='wilcoxon'\n",
    "#     )\n",
    "\n",
    "#     de_results_df = sc.get.rank_genes_groups_df(\n",
    "#         adata_deg,\n",
    "#         group=pert\n",
    "#     )\n",
    "\n",
    "#     top_degs = de_results_df[\n",
    "#         (de_results_df['pvals_adj'] < 0.05) & \n",
    "#         (np.abs(de_results_df['logfoldchanges']) > 0.5)\n",
    "#     ]\n",
    "\n",
    "#     # print(f\"len(top_degs): {len(top_degs)}\")\n",
    "\n",
    "#     pert_degs = top_degs['names'].values.tolist()\n",
    "\n",
    "#     # print(pert_degs)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         z_control = model_ae.encode(X_ctrl)\n",
    "\n",
    "#         pert_idx = torch.tensor([global_perturb_to_idx[pert]] * X_ctrl.shape[0], device=device)\n",
    "#         control_cell_types = adata.obs.loc[ctrl_mask, 'cell_type'].values\n",
    "#         cond_indices = [global_condition_to_idx[ct] for ct in control_cell_types]\n",
    "#         cond_tensor = torch.tensor(cond_indices, device=device)\n",
    "\n",
    "#         z_pred = flow_model.integrate(\n",
    "#                 x0=z_control, \n",
    "#                 t0=0.0, \n",
    "#                 t1=1.0, \n",
    "#                 perturbations=pert_idx,\n",
    "#                 conditions=cond_tensor\n",
    "#             )\n",
    "\n",
    "#         X_pred_treated_raw = sampler.sample(z_pred, library_sizes)\n",
    "\n",
    "#         wd_gene = compute_wd_per_gene(X_pred_treated_raw.cpu(), X_actual_treated_raw.cpu())\n",
    "\n",
    "#         # print(f'mean wd on test data: {wd_gene.mean()}')\n",
    "    \n",
    "#         wds.append(wd_gene)\n",
    "\n",
    "#         deg_indices = [adata.var_names.get_loc(g) for g in pert_degs if g in adata.var_names]\n",
    "#         wd_degs = wd_gene[deg_indices]\n",
    "#         deg_wds_list.extend(wd_degs)\n",
    "\n",
    "#         # print(wd_degs)\n",
    "\n",
    "# np.array(deg_wds_list).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec7a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ZINBSampler(model_ae, device=device)\n",
    "\n",
    "for pert in heldout_perts:\n",
    "    treated_mask = (adata.obs['perturbation'] == pert) & (adata.obs['donor'] != holdout_donor)\n",
    "    # treated_mask = (adata.obs['donor'] == holdout_donor) & (adata.obs['perturbation'] == pert)\n",
    "\n",
    "    X_ctrl = torch.from_numpy(adata[ctrl_mask].X.toarray().astype(\"float32\")).to(device)\n",
    "    X_actual_treated_raw = torch.from_numpy(adata[treated_mask].layers['counts'].toarray().astype(\"float32\")).to(device)\n",
    "    library_sizes = torch.from_numpy(adata.layers['counts'][ctrl_mask].sum(1)).float().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        z_control = model_ae.encode(X_ctrl)\n",
    "\n",
    "        pert_idx = torch.tensor([global_perturb_to_idx[pert]] * X_ctrl.shape[0], device=device)\n",
    "        control_cell_types = adata.obs.loc[ctrl_mask, 'cell_type'].values\n",
    "        cond_indices = [global_condition_to_idx[ct] for ct in control_cell_types]\n",
    "        cond_tensor = torch.tensor(cond_indices, device=device)\n",
    "\n",
    "        z_pred = flow_model.integrate(\n",
    "                x0=z_control, \n",
    "                t0=0.0, \n",
    "                t1=1.0, \n",
    "                perturbations=pert_idx,\n",
    "                conditions=cond_tensor\n",
    "            )\n",
    "\n",
    "        X_pred_treated_raw = sampler.sample(z_pred, library_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_gene.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12175ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p98_wd = np.percentile(wd_gene, 99.8)\n",
    "print(f\"98th Percentile WD: {p98_wd:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6216e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(wd_gene, stat='density', discrete=True, color='blue', alpha=0.4, label='true treated', element='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_expression = X_actual_treated_raw.mean(dim=0)\n",
    "top_values, top_indices = torch.topk(mean_expression, k=10)\n",
    "top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c6c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_idx = 849\n",
    "x_pred = X_pred_treated_raw[:, gene_idx].cpu().numpy()\n",
    "x_true = X_actual_treated_raw[:, gene_idx].cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "sns.histplot(x_true, stat='density', discrete=True, color='blue', alpha=0.4, label='true treated', element='step')\n",
    "sns.histplot(x_pred, stat='density', discrete=True, color='orange', alpha=0.4, label='pred treated', element='step')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eb6962",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_pred_treated_raw.shape)\n",
    "print(X_actual_treated_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499354c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_gene.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dcbaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_model.eval()\n",
    "\n",
    "# x_0_list, x_1_list, x_pred_list, cond_list = [], [], [], []\n",
    "\n",
    "# for split, loader in zip([\"train\", \"test\"], [train_loader, test_loader]):\n",
    "# # for split, loader in zip([\"train\"], [train_loader]):\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in loader:\n",
    "#             x_0 = batch[\"x_0\"].to(device)\n",
    "#             x_1 = batch[\"x_1\"].to(device)\n",
    "#             perturb = batch[\"perturb\"].to(device)\n",
    "#             conditions = batch[\"condition\"].to(device)\n",
    "#             x_pred = flow_model.integrate(x_0, 0.0, 1.0, perturbations=perturb, conditions=conditions)\n",
    "#             x_0_list.append(x_0.detach().cpu())\n",
    "#             x_1_list.append(x_1.detach().cpu())\n",
    "#             x_pred_list.append(x_pred.detach().cpu())\n",
    "#             cond_list.append(conditions.detach().cpu())\n",
    "\n",
    "#     X_0 = torch.cat(x_0_list, dim=0).numpy()\n",
    "#     X_1 = torch.cat(x_1_list, dim=0).numpy()\n",
    "#     X_pred = torch.cat(x_pred_list)\n",
    "#     cond_all = torch.cat(cond_list, dim=0).numpy()\n",
    "#     cond_all = cond_all.squeeze().astype(str)\n",
    "\n",
    "#     print(f\"split: {split}, cond_all: {cond_all}\")\n",
    "\n",
    "#     X_all = np.vstack([X_0, X_1, X_pred])\n",
    "\n",
    "#     pca = PCA(n_components=2, random_state=0)\n",
    "#     pca.fit(np.vstack([X_0, X_1]))\n",
    "#     Z_all = pca.transform(X_all)\n",
    "\n",
    "#     Z0 = Z_all[:len(X_0)]\n",
    "#     Z1 = Z_all[len(X_0):len(Z_all)-len(X_pred)]\n",
    "#     X_pred_pca = Z_all[len(Z_all)-len(X_pred):]\n",
    "\n",
    "#     df = pd.DataFrame({\n",
    "#         \"pc1\": np.concatenate([Z0[:,0], Z1[:,0], X_pred_pca[:, 0]]),\n",
    "#         \"pc2\": np.concatenate([Z0[:,1], Z1[:,1], X_pred_pca[:, 1]]),\n",
    "#         \"split\": [\"x_0 (control)\"]*len(Z0) + [\"x_1 (perturbed)\"]*len(Z1) + [\"x_1 (predicted)\"]*len(X_pred_pca),\n",
    "#         \"cond\": cond_all.tolist() + [None] * (len(Z1) + len(X_pred_pca)),\n",
    "#     })\n",
    "\n",
    "#     fig = px.scatter(df, x=\"pc1\", y=\"pc2\", color=\"split\", opacity=0.6, title=f\"{split} set in PCA space\", width=600, height=500)\n",
    "#     fig.show()\n",
    "\n",
    "#     # fig = px.scatter(df, x=\"pc1\", y=\"pc2\", color=\"cond\", opacity=0.6, title=f\"{split} set in PCA space\", width=600, height=500)\n",
    "#     # fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.condition_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_idx).isdisjoint(set(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c25be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.index[1011]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe4a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.asarray(adata.X.mean(axis=0)).flatten()\n",
    "top_n_indices = np.argsort(scores)[::-1][:10]\n",
    "top_n_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e06a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['cytokine'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2786fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.perturbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e24776",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_effects = {}\n",
    "\n",
    "for pert in test_dataset.perturbs:\n",
    "\n",
    "    if pert == 'PBS':\n",
    "        continue\n",
    "\n",
    "    print(\"----\" * 10)\n",
    "    print(f\"pert: {pert}\")\n",
    "\n",
    "    test_adata = adata[adata.obs['cytokine'].isin(['PBS', pert])].copy()\n",
    "\n",
    "    sc.tl.rank_genes_groups(\n",
    "        test_adata,\n",
    "        groupby='cytokine',\n",
    "        groups=[pert],\n",
    "        reference='PBS',\n",
    "        method='wilcoxon'\n",
    "    )\n",
    "\n",
    "    de_results_df = sc.get.rank_genes_groups_df(\n",
    "        test_adata,\n",
    "        group=pert\n",
    "    )\n",
    "\n",
    "    top_degs = de_results_df[\n",
    "        (de_results_df['pvals_adj'] < 0.05) & \n",
    "        (np.abs(de_results_df['logfoldchanges']) > 0.5)\n",
    "    ].head(20)\n",
    "\n",
    "    print(top_degs[['names', 'pvals_adj', 'logfoldchanges']])\n",
    "\n",
    "    sig_effects[pert] = []\n",
    "    for gene, fold_change in zip(top_degs['names'], top_degs['logfoldchanges']):\n",
    "        sig_effects[pert].append((gene, fold_change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b945e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7af11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERTURBATION = 'IL-15' # 'IL-7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01251574",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(adata.var.index == 'IFIT3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scvi.distributions import ZeroInflatedNegativeBinomial\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "mmds = []\n",
    "wds = []\n",
    "\n",
    "for pert, effects in sig_effects.items():\n",
    "    \n",
    "    if len(effects) == 0:\n",
    "        continue\n",
    "\n",
    "    for sig_gene, fold_change in effects:\n",
    "\n",
    "        print(f'pert: {pert}, gene: {sig_gene}, fold_change: {fold_change}')\n",
    "\n",
    "        gene_idx = np.where(adata.var.index == sig_gene)[0][0]\n",
    "\n",
    "        # gene_idx = 329\n",
    "        # donor_id = 'Donor1'\n",
    "\n",
    "        # target_donors = adata.obs['donor'].unique()\n",
    "        # split_mask = np.zeros(adata.n_obs, dtype=bool)\n",
    "        # split_mask[train_idx] = True\n",
    "\n",
    "        target_donors = ['Donor1']\n",
    "        split_mask = np.zeros(adata.n_obs, dtype=bool)\n",
    "        split_mask[test_idx] = True\n",
    "\n",
    "        donor_mask = adata.obs['donor'].isin(target_donors)\n",
    "\n",
    "        control_mask = (adata.obs['cytokine'] == 'PBS') & split_mask & donor_mask\n",
    "        treated_mask = (adata.obs['cytokine'] == pert) & split_mask & donor_mask\n",
    "\n",
    "        x_control_tensor = torch.from_numpy(adata[control_mask].X.toarray().astype(\"float32\")).to(device)\n",
    "        x_treated_tensor = torch.from_numpy(adata[treated_mask].X.toarray().astype(\"float32\")).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z_control = model_ae.encode(x_control_tensor)\n",
    "            z_treated = model_ae.encode(x_treated_tensor)\n",
    "\n",
    "            pert_idx = train_dataset.perturb_to_idx[pert]\n",
    "\n",
    "            control_cell_types = adata.obs.loc[control_mask, 'cell_type'].values\n",
    "            cond_indices = [train_dataset.condition_to_idx[ct] for ct in control_cell_types]\n",
    "            cond_tensor = torch.tensor(cond_indices, device=device)\n",
    "\n",
    "            z_pred = flow_model.integrate(\n",
    "                x0=z_control, \n",
    "                t0=0.0, \n",
    "                t1=1.0, \n",
    "                perturbations=pert_idx,\n",
    "                conditions=cond_tensor\n",
    "            )\n",
    "\n",
    "        batch_size = z_control.shape[0]\n",
    "        pert_tensor = torch.tensor([pert_idx], device=device).repeat(batch_size)\n",
    "\n",
    "        h_decoded = model_ae.decoder(z_pred)\n",
    "\n",
    "\n",
    "        pred_proportions = model_ae.decoder_mean(h_decoded)\n",
    "        pred_dropout = model_ae.decoder_dropout(h_decoded)\n",
    "        pred_dispersion = torch.exp(model_ae.decoder_dispersion)\n",
    "\n",
    "        batch_proportions = pred_proportions[:, gene_idx]\n",
    "        batch_dropout = pred_dropout[:, gene_idx]\n",
    "        gene_theta = torch.exp(model_ae.decoder_dispersion)[gene_idx]\n",
    "        batch_theta = gene_theta.repeat(batch_proportions.shape[0])\n",
    "        batch_library_size = torch.from_numpy(\n",
    "            adata.layers['counts'][control_mask.values].sum(axis=1)\n",
    "        ).float().to(device).flatten()\n",
    "\n",
    "        dist = ZeroInflatedNegativeBinomial(\n",
    "            mu=batch_proportions * batch_library_size,           \n",
    "            theta=gene_theta,     \n",
    "            zi_logits=batch_dropout,\n",
    "        )\n",
    "\n",
    "        synthetic_treated_counts = dist.sample().cpu().numpy()\n",
    "        real_control_counts = adata.layers['counts'][control_mask.values, gene_idx].toarray().flatten()\n",
    "        real_treated_counts = adata.layers['counts'][treated_mask.values, gene_idx].toarray().flatten()\n",
    "\n",
    "        plt.figure(figsize=(5, 3))\n",
    "\n",
    "        sns.histplot(real_control_counts, label='observed control', fill=True, stat='density', discrete=True, element='step', color='gray')\n",
    "        sns.histplot(real_treated_counts, label='observed treated', fill=True, stat='density', discrete=True, element='step', color='green')\n",
    "        sns.histplot(synthetic_treated_counts, label='model prediction treated', fill=True, stat='density', discrete=True, element='step', color='blue', alpha=0.2)\n",
    "\n",
    "        wd = wasserstein_distance(real_treated_counts, synthetic_treated_counts)\n",
    "        print(f\"Gene {sig_gene}: Wasserstein Distance = {wd:.4f}\")\n",
    "        wds.append(wd)\n",
    "\n",
    "        plt.title(f\"model fit for gene {adata.var_names[gene_idx]}\")\n",
    "        plt.xlabel(\"gene expression raw\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    z_all = torch.cat([z_control, z_treated, z_pred], dim=0).cpu().numpy()\n",
    "    diff_vector = z_treated.mean(0) - z_control.mean(0)\n",
    "    diff_vector = diff_vector / diff_vector.norm()\n",
    "    proj_control = (z_control @ diff_vector).cpu().numpy()\n",
    "    proj_treated = (z_treated @ diff_vector).cpu().numpy()\n",
    "    proj_pred = (z_pred @ diff_vector).cpu().numpy()\n",
    "\n",
    "    mu_c = proj_control.mean()\n",
    "    std_c = proj_control.std()\n",
    "\n",
    "    norm_control = (proj_control - mu_c) / std_c\n",
    "    norm_treated = (proj_treated - mu_c) / std_c\n",
    "    norm_pred = (proj_pred - mu_c) / std_c\n",
    "\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.kdeplot(norm_control, fill=True, label='control', color='gray')\n",
    "    sns.kdeplot(norm_treated, fill=True, label='treated', color='green')\n",
    "    sns.kdeplot(norm_pred, fill=True, label='predicted', color='blue')\n",
    "\n",
    "    x_true = norm_treated.reshape(-1, 1)\n",
    "    x_pred = norm_pred.reshape(-1, 1)\n",
    "    mmd = compute_mmd(x_true, x_pred)\n",
    "    print(f\"mmd: {mmd:.4f}\")\n",
    "\n",
    "    mmds.append(mmd)\n",
    "\n",
    "    plt.title(f\"projection onto perturbation axis for {pert}\")\n",
    "    plt.xlabel(\"latent score AU\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# print(f\"avg mmd: {np.array(mmds).mean():.4f}\")\n",
    "\n",
    "print(f\"avg wd: {np.array(wds).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "perturb_embedding = np.array(flow_model.perturb_emb.weight.detach().cpu().numpy())\n",
    "pca_result = PCA(n_components=2).fit_transform(perturb_embedding)\n",
    "reducer = umap.UMAP(n_components=2)\n",
    "umap_result = reducer.fit_transform(perturb_embedding)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].scatter(pca_result[:, 0], pca_result[:, 1])\n",
    "ax[0].set_title(\"PCA\")\n",
    "ax[1].scatter(umap_result[:, 0], umap_result[:, 1])\n",
    "ax[0].set_title(\"UMAP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ce1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
